{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\dhruv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk import FreqDist \n",
    "from nltk import pos_tag\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from collections import Counter\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" Counting tags are crucial for text classification as well as preparing the features for the Natural language-based operations.I will be discussing with you the approach which guru99 followed while preparing code along with a discussion of output. Hope this will help you.Frequency Distribution is referred to as the number of times an outcome of an experiment occurs. It is used to find the frequency of each word occurring in a document.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('counting', 'NN'), ('tags', 'NNS'), ('are', 'VBP'), ('crucial', 'JJ'), ('for', 'IN'), ('text', 'JJ'), ('classification', 'NN'), ('as', 'RB'), ('well', 'RB'), ('as', 'IN'), ('preparing', 'VBG'), ('the', 'DT'), ('features', 'NNS'), ('for', 'IN'), ('the', 'DT'), ('natural', 'JJ'), ('language-based', 'JJ'), ('operations.i', 'NN'), ('will', 'MD'), ('be', 'VB'), ('discussing', 'VBG'), ('with', 'IN'), ('you', 'PRP'), ('the', 'DT'), ('approach', 'NN'), ('which', 'WDT'), ('guru99', 'VBP'), ('followed', 'VBN'), ('while', 'IN'), ('preparing', 'VBG'), ('code', 'NN'), ('along', 'IN'), ('with', 'IN'), ('a', 'DT'), ('discussion', 'NN'), ('of', 'IN'), ('output', 'NN'), ('.', '.'), ('hope', 'NN'), ('this', 'DT'), ('will', 'MD'), ('help', 'VB'), ('you.frequency', 'VB'), ('distribution', 'NN'), ('is', 'VBZ'), ('referred', 'VBN'), ('to', 'TO'), ('as', 'IN'), ('the', 'DT'), ('number', 'NN'), ('of', 'IN'), ('times', 'NNS'), ('an', 'DT'), ('outcome', 'NN'), ('of', 'IN'), ('an', 'DT'), ('experiment', 'NN'), ('occurs', 'VBZ'), ('.', '.'), ('it', 'PRP'), ('is', 'VBZ'), ('used', 'VBN'), ('to', 'TO'), ('find', 'VB'), ('the', 'DT'), ('frequency', 'NN'), ('of', 'IN'), ('each', 'DT'), ('word', 'NN'), ('occurring', 'VBG'), ('in', 'IN'), ('a', 'DT'), ('document', 'NN'), ('.', '.')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lower_case = text.lower()\n",
    "tokens = nltk.word_tokenize(lower_case)\n",
    "tags = nltk.pos_tag(tokens)\n",
    "print(tags)\n",
    "print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NN': 15, 'IN': 13, 'DT': 11, 'JJ': 4, 'VBG': 4, 'VB': 4, 'NNS': 3, 'VBN': 3, '.': 3, 'VBZ': 3, 'VBP': 2, 'RB': 2, 'MD': 2, 'PRP': 2, 'TO': 2, 'WDT': 1})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FreqDist({'the': 5, 'of': 4, 'as': 3, '.': 3, 'for': 2, 'preparing': 2, 'will': 2, 'with': 2, 'a': 2, 'is': 2, ...})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To count the tags, you can use the package Counter from the collection's module. A counter is a dictionary subclass which works on the principle of key-value operation. It is an unordered collection where elements are stored as a dictionary key while the count is their value.\n",
    "counts = Counter( tag for word,  tag in tags)\n",
    "print(counts)\n",
    "words = nltk.tokenize.word_tokenize(text)\n",
    "fd = nltk.FreqDist(words)\n",
    "fd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Counting', 'tags', 'are', 'crucial', 'for', 'text', 'classification', 'as', 'well', 'as', 'preparing', 'the', 'features', 'for', 'the', 'Natural', 'language-based', 'operations.I', 'will', 'be', 'discussing', 'with', 'you', 'the', 'approach', 'which', 'guru99', 'followed', 'while', 'preparing', 'code', 'along', 'with', 'a', 'discussion', 'of', 'output', '.', 'Hope', 'this', 'will', 'help', 'you.Frequency', 'Distribution', 'is', 'referred', 'to', 'as', 'the', 'number', 'of', 'times', 'an', 'outcome', 'of', 'an', 'experiment', 'occurs', '.', 'It', 'is', 'used', 'to', 'find', 'the', 'frequency', 'of', 'each', 'word', 'occurring', 'in', 'a', 'document', '.']\n",
      "[' Counting tags are crucial for text classification as well as preparing the features for the Natural language-based operations.I will be discussing with you the approach which guru99 followed while preparing code along with a discussion of output.', 'Hope this will help you.Frequency Distribution is referred to as the number of times an outcome of an experiment occurs.', 'It is used to find the frequency of each word occurring in a document.']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len():gives length\n",
    "tokens=word_tokenize(text)\n",
    "print(tokens)\n",
    "len(tokens)\n",
    "\n",
    "tokens=sent_tokenize(text)\n",
    "print(tokens)\n",
    "len(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'C', 'o', 'u', 'n', 't', 'i', 'n', 'g', ' ', 't', 'a', 'g', 's', ' ', 'a', 'r', 'e', ' ', 'c', 'r', 'u', 'c', 'i', 'a', 'l', ' ', 'f', 'o', 'r', ' ', 't', 'e', 'x', 't', ' ', 'c', 'l', 'a', 's', 's', 'i', 'f', 'i', 'c', 'a', 't', 'i', 'o', 'n', ' ', 'a', 's', ' ', 'w', 'e', 'l', 'l', ' ', 'a', 's', ' ', 'p', 'r', 'e', 'p', 'a', 'r', 'i', 'n', 'g', ' ', 't', 'h', 'e', ' ', 'f', 'e', 'a', 't', 'u', 'r', 'e', 's', ' ', 'f', 'o', 'r', ' ', 't', 'h', 'e', ' ', 'N', 'a', 't', 'u', 'r', 'a', 'l', ' ', 'l', 'a', 'n', 'g', 'u', 'a', 'g', 'e', '-', 'b', 'a', 's', 'e', 'd', ' ', 'o', 'p', 'e', 'r', 'a', 't', 'i', 'o', 'n', 's', '.', 'I', ' ', 'w', 'i', 'l', 'l', ' ', 'b', 'e', ' ', 'd', 'i', 's', 'c', 'u', 's', 's', 'i', 'n', 'g', ' ', 'w', 'i', 't', 'h', ' ', 'y', 'o', 'u', ' ', 't', 'h', 'e', ' ', 'a', 'p', 'p', 'r', 'o', 'a', 'c', 'h', ' ', 'w', 'h', 'i', 'c', 'h', ' ', 'g', 'u', 'r', 'u', '9', '9', ' ', 'f', 'o', 'l', 'l', 'o', 'w', 'e', 'd', ' ', 'w', 'h', 'i', 'l', 'e', ' ', 'p', 'r', 'e', 'p', 'a', 'r', 'i', 'n', 'g', ' ', 'c', 'o', 'd', 'e', ' ', 'a', 'l', 'o', 'n', 'g', ' ', 'w', 'i', 't', 'h', ' ', 'a', ' ', 'd', 'i', 's', 'c', 'u', 's', 's', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 'o', 'u', 't', 'p', 'u', 't', '.', ' ', 'H', 'o', 'p', 'e', ' ', 't', 'h', 'i', 's', ' ', 'w', 'i', 'l', 'l', ' ', 'h', 'e', 'l', 'p', ' ', 'y', 'o', 'u', '.', 'F', 'r', 'e', 'q', 'u', 'e', 'n', 'c', 'y', ' ', 'D', 'i', 's', 't', 'r', 'i', 'b', 'u', 't', 'i', 'o', 'n', ' ', 'i', 's', ' ', 'r', 'e', 'f', 'e', 'r', 'r', 'e', 'd', ' ', 't', 'o', ' ', 'a', 's', ' ', 't', 'h', 'e', ' ', 'n', 'u', 'm', 'b', 'e', 'r', ' ', 'o', 'f', ' ', 't', 'i', 'm', 'e', 's', ' ', 'a', 'n', ' ', 'o', 'u', 't', 'c', 'o', 'm', 'e', ' ', 'o', 'f', ' ', 'a', 'n', ' ', 'e', 'x', 'p', 'e', 'r', 'i', 'm', 'e', 'n', 't', ' ', 'o', 'c', 'c', 'u', 'r', 's', '.', ' ', 'I', 't', ' ', 'i', 's', ' ', 'u', 's', 'e', 'd', ' ', 't', 'o', ' ', 'f', 'i', 'n', 'd', ' ', 't', 'h', 'e', ' ', 'f', 'r', 'e', 'q', 'u', 'e', 'n', 'c', 'y', ' ', 'o', 'f', ' ', 'e', 'a', 'c', 'h', ' ', 'w', 'o', 'r', 'd', ' ', 'o', 'c', 'c', 'u', 'r', 'r', 'i', 'n', 'g', ' ', 'i', 'n', ' ', 'a', ' ', 'd', 'o', 'c', 'u', 'm', 'e', 'n', 't', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "sw=[i for i in text if not i is stopwords.words()]\n",
    "print(sw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
